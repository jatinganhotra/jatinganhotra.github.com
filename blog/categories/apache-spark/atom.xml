<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Apache Spark | blog@jatinganhotra]]></title>
  <link href="http://jatinganhotra.com/blog/categories/apache-spark/atom.xml" rel="self"/>
  <link href="http://jatinganhotra.com/"/>
  <updated>2016-06-19T04:00:09-04:00</updated>
  <id>http://jatinganhotra.com/</id>
  <author>
    <name><![CDATA[Jatin Ganhotra]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Run &amp; Debug Spark apps in IntelliJ IDEA]]></title>
    <link href="http://jatinganhotra.com/blog/2015/12/07/run-and-debug-spark-apps-in-intellij-idea/"/>
    <updated>2015-12-07T22:21:00-05:00</updated>
    <id>http://jatinganhotra.com/blog/2015/12/07/run-and-debug-spark-apps-in-intellij-idea</id>
    <content type="html"><![CDATA[<p><link href='http://fonts.googleapis.com/css?family=Coming+Soon&subset=latin,latin-ext' rel='stylesheet' type='text/css'></p>

<div>
<span style="float:right;" id="google_translate_element"></span>
<span style="float:right; font-family: 'Coming Soon', cursive;">Having trouble viewing in English, Choose Your Language : &nbsp;&nbsp;&nbsp;</span>
</div>


<BR>&nbsp;<BR>


<p>For my current research project, I needed to debug Spark core source code, to delve deeper
into the code and figure out the reason behind the unexpected experimental results.</p>

<p>I spent days trying to setup everything to debug my application, which ideally should have been
an hour or 2, considering that Spark is one of the <a href="https://blogs.apache.org/foundation/entry/the_apache_software_foundation_announces50">most active community open-source project on Apache</a>
right now.</p>

<p>I did find some posts and articles on the Internet and Spark user+dev mailing lists, but they were outdated, didn't account for all potential issues and didn't cover much details.</p>

<p>I finally got everything up and running, so here's a post listing down exact steps to get everything setup
for debugging Spark source code.</p>

<p>This post will cover setting up the environment for Mac OS X, but the same steps should work for any UNIX system.</p>

<h4>1. Install the Xcode Command Line Tools</h4>

<p>Installing command line tools has changed slightly than previous versions of MAC OS. Now you don't have to install Xcode , you can install Command Line Tools stand alone.<br/>
Type <code>xcode-select --install</code> in terminal and choose <em>Install</em> option from the pop-up.<br/>
This may take some time depending on your Internet connection.</p>

<h4>2. Install Homebrew</h4>

<p>I'm assuming you know about Homebrew, but if you don't do yourself a favor, my friend and install it by following <a href="https://github.com/mxcl/homebrew/wiki/installation">Homebrew's installation instructions</a>.</p>

<h4>3. Install Scala</h4>

<p>In Terminal enter</p>

<p>brew install scala --with-docs</p>

<h4>4. Download and Install IntelliJ IDEA</h4>

<p>Hop-over to the JetBrains website and download <a href="https://www.jetbrains.com/idea/download/">IntelliJ IDEA 15</a> (the latest version right now). The Community Edition is free and the same steps should work for any other version too.
On the first-run, IntelliJ might ask for setting up the Scala featured plugin. Ignore that option, as we will link IntelliJ to our Mac OS's Homebrew scala installation.</p>

<h4>5. Download and Building Spark</h4>

<p>Download the Spark Source Code from the <a href="http://spark.apache.org/downloads.html">Spark website</a> - latest version - Spark 1.5.2 (Nov 09 2015).</p>

<p>To produce a Spark package compiled with Scala 2.11, use the -Dscala-2.11 property as mentioned <a href="http://spark.apache.org/docs/latest/building-spark.html#building-for-scala-211">here</a>:</p>

<p>./dev/change-scala-version.sh 2.11
mvn -Pyarn -Phadoop-2.4 -Dscala-2.11 -DskipTests clean package</p>

<p>If you get the error -
org.apache.spark.SparkException: An application name must be set in your configuration
val configuration = new SparkConf()</p>

<pre><code>            .setAppName("Your Application Name")
            .setMaster("local");
</code></pre>

<p>Install Scala &amp; SBT plugins for IntelliJ before anything</p>

<p>When creating your application, follow these steps :-
1. Create New project
2. Choose Scala - Scala (Simple module with attached Scala SDK) (Don't use SBT)
3. In project SDK, choose New JDK and select the path to the JAVA JDK Home
e.g. /Library/Java/JavaVirtualMachines/jdk1.8.0_31.jdk/Contents/Home
4. In Scala SDK, choose Create - Browse and select the path to Scala SDK
/usr/local/Cellar/scala/2.11.7/libexec</p>

<p>Create New Scala script under src folder named SimpleApp.scala and
paste the following code - taken from <a href="http://spark.apache.org/docs/latest/quick-start.html#self-contained-applications">Spark QuickStart guide</a></p>

<p>/<em> SimpleApp.scala </em>/
import org.apache.spark.SparkContext
import org.apache.spark.SparkContext._
import org.apache.spark.SparkConf</p>

<p>object SimpleApp {
  def main(args: Array[String]) {</p>

<pre><code>val logFile = "YOUR_SPARK_HOME/README.md" // Should be some file on your system
val conf = new SparkConf().setAppName("Simple Application")
val sc = new SparkContext(conf)
val logData = sc.textFile(logFile, 2).cache()
val numAs = logData.filter(line =&gt; line.contains("a")).count()
val numBs = logData.filter(line =&gt; line.contains("b")).count()
println("Lines with a: %s, Lines with b: %s".format(numAs, numBs))
</code></pre>

<p>  }
}</p>

<p>So far, we haven't added Spark to our application. To add Spark library,
Click File -> Project Structure. Under Libraries, add Java
and select
SPARK_FOLDER/spark-1.5.2/assembly/target/scala-2.11/spark-assembly-1.5.2-hadoop2.4.0.jar</p>

<p>This step may take some time (1-5 mins), while IntelliJ is indexing.</p>

<p>6) Final step. Run it!</p>

<p>Click Run-> Edit Configuration and click + on the left side, then choose Application.</p>

<p>Paste</p>

<p>-Dspark.master=local to VM option, and get the App name matching your object name (which is MySimpleApp in my case).</p>

<p>The application should run fine.
Now, let's debug the application by setting a breakpoint on the filter command.</p>

<p>When you reach the breakpoint and Step Into, IntelliJ would complain about Sources not found
and show options to Download or Attach Sources</p>

<p>Since, we already have spark source code downloaded, we can simply attach them.
Select Attach Sources and select the SPARK_FOLDER
Click OK to add all sources for all folders in SPARK_FOLDER.</p>

<p>Again, IntelliJ may take some time (1-5 mins) to index all the sources we just added.
Once the indexing is completed, you can resume the debugging and everything should work smoothly.</p>

<p>Other articles -
[SBT-based Scala project, with SBT and Scala plugins installed on IntelliJ]
(https://www.linkedin.com/pulse/develop-apache-spark-apps-intellij-idea-windows-os-samuel-yee)</p>

<p>Helpful
http://hackers-duffers.logdown.com/posts/245018-configuring-spark-with-intellij</p>

<p>http://www.sparktutorials.net/building-apache-spark-on-your-local-machine</p>

<p>Tried this link, but many issues
http://kylinx.com/spark/Debug-Spark-in-IntelliJ.htm</p>

<p>Apache Spark Dev list
http://apache-spark-developers-list.1001551.n3.nabble.com/Intro-to-using-IntelliJ-to-debug-SPARK-1-1-Apps-with-mvn-sbt-for-beginners-td9429.html
and
http://apache-spark-developers-list.1001551.n3.nabble.com/Spark-1-5-0-setting-up-debug-env-td14056.html</p>

<p>Another post (not tried yet, but could be helpful)
http://danosipov.com/?p=779</p>

<p>Kind of similar to my approach, but missing some steps
https://docs.sigmoidanalytics.com/index.php/Step_by_Step_instructions_on_how_to_build_Spark_App_with_IntelliJ_IDEA</p>

<p>Seems relevant, but not so much helpful
https://github.com/mesos/spark/wiki/Spark-Debugger</p>

<p>Mention this link at the end - Useful developer tools - Spark
https://cwiki.apache.org/confluence/display/SPARK/Useful+Developer+Tools#UsefulDeveloperTools-IDESetup</p>

<p>After finishing the article, post answers to the questions:
http://stackoverflow.com/search?q=debug+spark</p>
]]></content>
  </entry>
  
</feed>
